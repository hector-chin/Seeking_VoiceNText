{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c89c9f1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tibame_T14\\anaconda3\\lib\\site-packages\\ckiptagger\\model_ws.py:106: UserWarning: `tf.nn.rnn_cell.LSTMCell` is deprecated and will be removed in a future version. This class is equivalent as `tf.keras.layers.LSTMCell`, and will be replaced by that in Tensorflow 2.0.\n",
      "  cell = tf.compat.v1.nn.rnn_cell.LSTMCell(hidden_d, name=name)\n",
      "C:\\Users\\Tibame_T14\\anaconda3\\lib\\site-packages\\keras\\layers\\legacy_rnn\\rnn_cell_impl.py:984: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use `layer.add_weight` method instead.\n",
      "  self._kernel = self.add_variable(\n",
      "C:\\Users\\Tibame_T14\\anaconda3\\lib\\site-packages\\keras\\layers\\legacy_rnn\\rnn_cell_impl.py:993: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use `layer.add_weight` method instead.\n",
      "  self._bias = self.add_variable(\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from ckiptagger import construct_dictionary, WS, POS\n",
    "ws = WS(\"./data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "419d06d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./youtube/醫療保健text.json') as f:\n",
    "    data = json.loads(f.read())\n",
    "with open('./stopword.txt', encoding='utf-8') as f:\n",
    "    stop = f.read()\n",
    "stopword = stop.split('\\n')\n",
    "# 使用分好詞的資料\n",
    "alltext = []\n",
    "for file in data.values():\n",
    "    for name, texts in file.items():\n",
    "        word_sentence_list = ws(list(texts))\n",
    "        text_list = []\n",
    "        for i in range(len(texts)):\n",
    "            for word in word_sentence_list[i]:\n",
    "                if word not in stopword:\n",
    "                    text_list.append(word)\n",
    "        if text_list != []:\n",
    "            alltext.append(text_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "050587a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "model1 = Word2Vec(sentences=alltext, min_count=1, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cd518386",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.corpora import Dictionary\n",
    "dct = Dictionary(alltext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ae6d1c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "maxlen = 0\n",
    "for i in [len(k) for k in alltext]:\n",
    "    if i > maxlen:\n",
    "        maxlen = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5e3f3e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "for document in alltext:\n",
    "    doc = model1.wv[document]\n",
    "    doclist = []\n",
    "    for i in doc:\n",
    "        num = []\n",
    "        for n in i:\n",
    "            num.append(n)\n",
    "        doclist.append(num)\n",
    "    doclen = len(doclist)\n",
    "    for k in range(maxlen-doclen):\n",
    "        doclist.append([len(dct) for _ in range(100)])\n",
    "    X.append(doclist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d7f6e87e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "y = [str(random.randint(0,3)) for _ in range(len(alltext))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0f09a8ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test= train_test_split(X,y,test_size=0.3,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "94dffe7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)           [(None, 100)]        0           []                               \n",
      "                                                                                                  \n",
      " embedding_1 (Embedding)        (None, 100, 300)     8006400     ['input_2[0][0]']                \n",
      "                                                                                                  \n",
      " conv1d_3 (Conv1D)              (None, 100, 256)     230656      ['embedding_1[0][0]']            \n",
      "                                                                                                  \n",
      " conv1d_4 (Conv1D)              (None, 100, 256)     307456      ['embedding_1[0][0]']            \n",
      "                                                                                                  \n",
      " conv1d_5 (Conv1D)              (None, 100, 256)     384256      ['embedding_1[0][0]']            \n",
      "                                                                                                  \n",
      " max_pooling1d_3 (MaxPooling1D)  (None, 2, 256)      0           ['conv1d_3[0][0]']               \n",
      "                                                                                                  \n",
      " max_pooling1d_4 (MaxPooling1D)  (None, 2, 256)      0           ['conv1d_4[0][0]']               \n",
      "                                                                                                  \n",
      " max_pooling1d_5 (MaxPooling1D)  (None, 2, 256)      0           ['conv1d_5[0][0]']               \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 2, 768)       0           ['max_pooling1d_3[0][0]',        \n",
      "                                                                  'max_pooling1d_4[0][0]',        \n",
      "                                                                  'max_pooling1d_5[0][0]']        \n",
      "                                                                                                  \n",
      " flatten_1 (Flatten)            (None, 1536)         0           ['concatenate_1[0][0]']          \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 1536)         0           ['flatten_1[0][0]']              \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 4)            6148        ['dropout_1[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 8,934,916\n",
      "Trainable params: 928,516\n",
      "Non-trainable params: 8,006,400\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import *\n",
    "\n",
    "main_input = Input(shape=(100,), dtype='float64')\n",
    "# 嵌入层（使用预训练的词向量）\n",
    "embedder = Embedding(len(dct) + 1, 300, input_length=100, trainable=False)\n",
    "embed = embedder(main_input)\n",
    "# 卷积层和池化层，设置卷积核大小分别为3,4,5\n",
    "cnn1 = Conv1D(256, 3, padding='same', strides=1, activation='relu')(embed)\n",
    "cnn1 = MaxPooling1D(pool_size=48)(cnn1)\n",
    "cnn2 = Conv1D(256, 4, padding='same', strides=1, activation='relu')(embed)\n",
    "cnn2 = MaxPooling1D(pool_size=47)(cnn2)\n",
    "cnn3 = Conv1D(256, 5, padding='same', strides=1, activation='relu')(embed)\n",
    "cnn3 = MaxPooling1D(pool_size=46)(cnn3)\n",
    "# 合并三个模型的输出向量\n",
    "cnn = concatenate([cnn1, cnn2, cnn3], axis=-1)\n",
    "flat = Flatten()(cnn)\n",
    "drop = Dropout(0.2)(flat) #在池化层到全连接层之前可以加上dropout防止过拟合\n",
    "main_output = Dense(4, activation='softmax')(drop)\n",
    "model = Model(inputs=main_input, outputs=main_output)\n",
    "model.summary()\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",optimizer=\"adam\",metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa83872",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x=X_train,y=y_train, validation_split=0.1, epochs=10, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "003132e7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
