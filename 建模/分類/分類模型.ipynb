{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "01646da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time\n",
    "from joblib import dump \n",
    "# 輸入要訓練的資料\n",
    "# TrainData_W2V.csv and TrainData_TFIDF.csv\n",
    "data = pd.read_csv('TrainData_W2V.csv')\n",
    "data['y'] = [0 for _ in range(len(data))]\n",
    "# 將資料分成訓練集跟測試集\n",
    "X_train,X_test,y_train,y_test= train_test_split(data.iloc[:,:-1],data.iloc[:,-1],test_size=0.3,random_state=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cd51fb0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>291</th>\n",
       "      <th>292</th>\n",
       "      <th>293</th>\n",
       "      <th>294</th>\n",
       "      <th>295</th>\n",
       "      <th>296</th>\n",
       "      <th>297</th>\n",
       "      <th>298</th>\n",
       "      <th>299</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.198767</td>\n",
       "      <td>0.452462</td>\n",
       "      <td>0.012118</td>\n",
       "      <td>0.232854</td>\n",
       "      <td>-0.385792</td>\n",
       "      <td>-0.078174</td>\n",
       "      <td>0.368550</td>\n",
       "      <td>0.404252</td>\n",
       "      <td>0.298668</td>\n",
       "      <td>0.086156</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.096112</td>\n",
       "      <td>0.443278</td>\n",
       "      <td>-0.128233</td>\n",
       "      <td>0.235329</td>\n",
       "      <td>0.169030</td>\n",
       "      <td>0.338615</td>\n",
       "      <td>-0.160767</td>\n",
       "      <td>0.040528</td>\n",
       "      <td>0.301025</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.116299</td>\n",
       "      <td>0.426314</td>\n",
       "      <td>0.043963</td>\n",
       "      <td>0.306998</td>\n",
       "      <td>-0.347162</td>\n",
       "      <td>-0.091148</td>\n",
       "      <td>0.400253</td>\n",
       "      <td>0.370823</td>\n",
       "      <td>0.328146</td>\n",
       "      <td>0.134766</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.103543</td>\n",
       "      <td>0.399193</td>\n",
       "      <td>-0.124846</td>\n",
       "      <td>0.311998</td>\n",
       "      <td>0.217576</td>\n",
       "      <td>0.335280</td>\n",
       "      <td>-0.184212</td>\n",
       "      <td>0.023380</td>\n",
       "      <td>0.276236</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.141312</td>\n",
       "      <td>0.219211</td>\n",
       "      <td>-0.047784</td>\n",
       "      <td>0.337363</td>\n",
       "      <td>-0.337504</td>\n",
       "      <td>-0.177875</td>\n",
       "      <td>0.259522</td>\n",
       "      <td>0.174175</td>\n",
       "      <td>0.315422</td>\n",
       "      <td>0.243993</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002533</td>\n",
       "      <td>0.536723</td>\n",
       "      <td>0.089167</td>\n",
       "      <td>0.151804</td>\n",
       "      <td>0.173900</td>\n",
       "      <td>0.226834</td>\n",
       "      <td>-0.034279</td>\n",
       "      <td>0.160243</td>\n",
       "      <td>0.231921</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.127328</td>\n",
       "      <td>0.454065</td>\n",
       "      <td>-0.015395</td>\n",
       "      <td>0.324827</td>\n",
       "      <td>-0.355668</td>\n",
       "      <td>-0.181511</td>\n",
       "      <td>0.409551</td>\n",
       "      <td>0.378628</td>\n",
       "      <td>0.283049</td>\n",
       "      <td>0.192282</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.037144</td>\n",
       "      <td>0.382995</td>\n",
       "      <td>-0.140089</td>\n",
       "      <td>0.290213</td>\n",
       "      <td>0.127780</td>\n",
       "      <td>0.332279</td>\n",
       "      <td>-0.121677</td>\n",
       "      <td>0.120118</td>\n",
       "      <td>0.320373</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.377168</td>\n",
       "      <td>0.415898</td>\n",
       "      <td>-0.106854</td>\n",
       "      <td>0.104183</td>\n",
       "      <td>0.002857</td>\n",
       "      <td>-0.044235</td>\n",
       "      <td>0.065276</td>\n",
       "      <td>-0.101596</td>\n",
       "      <td>0.252312</td>\n",
       "      <td>0.264270</td>\n",
       "      <td>...</td>\n",
       "      <td>0.202337</td>\n",
       "      <td>0.523531</td>\n",
       "      <td>-0.009183</td>\n",
       "      <td>0.320289</td>\n",
       "      <td>0.304284</td>\n",
       "      <td>0.008000</td>\n",
       "      <td>0.145484</td>\n",
       "      <td>0.176826</td>\n",
       "      <td>0.591520</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4130</th>\n",
       "      <td>0.261183</td>\n",
       "      <td>0.286592</td>\n",
       "      <td>-0.118561</td>\n",
       "      <td>0.118936</td>\n",
       "      <td>0.104597</td>\n",
       "      <td>-0.022623</td>\n",
       "      <td>0.111784</td>\n",
       "      <td>-0.200460</td>\n",
       "      <td>0.275091</td>\n",
       "      <td>0.311861</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.010332</td>\n",
       "      <td>0.494125</td>\n",
       "      <td>0.076149</td>\n",
       "      <td>0.288994</td>\n",
       "      <td>0.324444</td>\n",
       "      <td>-0.034715</td>\n",
       "      <td>0.127440</td>\n",
       "      <td>0.177613</td>\n",
       "      <td>0.509514</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4131</th>\n",
       "      <td>0.175034</td>\n",
       "      <td>0.276350</td>\n",
       "      <td>-0.197199</td>\n",
       "      <td>-0.011872</td>\n",
       "      <td>0.084094</td>\n",
       "      <td>-0.155784</td>\n",
       "      <td>0.166965</td>\n",
       "      <td>-0.173581</td>\n",
       "      <td>0.193364</td>\n",
       "      <td>0.237430</td>\n",
       "      <td>...</td>\n",
       "      <td>0.093888</td>\n",
       "      <td>0.437278</td>\n",
       "      <td>0.024422</td>\n",
       "      <td>0.260227</td>\n",
       "      <td>0.329413</td>\n",
       "      <td>-0.067035</td>\n",
       "      <td>0.169661</td>\n",
       "      <td>0.155913</td>\n",
       "      <td>0.517603</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4132</th>\n",
       "      <td>0.212616</td>\n",
       "      <td>0.196570</td>\n",
       "      <td>-0.204271</td>\n",
       "      <td>0.044122</td>\n",
       "      <td>0.007528</td>\n",
       "      <td>-0.147028</td>\n",
       "      <td>0.139173</td>\n",
       "      <td>-0.128615</td>\n",
       "      <td>0.216669</td>\n",
       "      <td>0.224261</td>\n",
       "      <td>...</td>\n",
       "      <td>0.088273</td>\n",
       "      <td>0.446130</td>\n",
       "      <td>-0.006519</td>\n",
       "      <td>0.148696</td>\n",
       "      <td>0.271967</td>\n",
       "      <td>0.048124</td>\n",
       "      <td>0.204842</td>\n",
       "      <td>0.145011</td>\n",
       "      <td>0.401621</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4133</th>\n",
       "      <td>0.238229</td>\n",
       "      <td>0.155935</td>\n",
       "      <td>-0.138760</td>\n",
       "      <td>-0.030620</td>\n",
       "      <td>0.082870</td>\n",
       "      <td>0.029618</td>\n",
       "      <td>0.092275</td>\n",
       "      <td>-0.177611</td>\n",
       "      <td>0.238138</td>\n",
       "      <td>0.309292</td>\n",
       "      <td>...</td>\n",
       "      <td>0.086252</td>\n",
       "      <td>0.566144</td>\n",
       "      <td>0.112057</td>\n",
       "      <td>0.301727</td>\n",
       "      <td>0.386718</td>\n",
       "      <td>-0.013566</td>\n",
       "      <td>0.137317</td>\n",
       "      <td>0.223767</td>\n",
       "      <td>0.488651</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4134</th>\n",
       "      <td>0.275128</td>\n",
       "      <td>0.242884</td>\n",
       "      <td>-0.190589</td>\n",
       "      <td>0.027736</td>\n",
       "      <td>0.210177</td>\n",
       "      <td>0.070173</td>\n",
       "      <td>0.021179</td>\n",
       "      <td>-0.257775</td>\n",
       "      <td>0.294246</td>\n",
       "      <td>0.277073</td>\n",
       "      <td>...</td>\n",
       "      <td>0.142902</td>\n",
       "      <td>0.431740</td>\n",
       "      <td>0.104178</td>\n",
       "      <td>0.211724</td>\n",
       "      <td>0.319531</td>\n",
       "      <td>0.063401</td>\n",
       "      <td>0.137556</td>\n",
       "      <td>0.258983</td>\n",
       "      <td>0.656513</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4135 rows × 301 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0         1         2         3         4         5         6  \\\n",
       "0     0.198767  0.452462  0.012118  0.232854 -0.385792 -0.078174  0.368550   \n",
       "1     0.116299  0.426314  0.043963  0.306998 -0.347162 -0.091148  0.400253   \n",
       "2     0.141312  0.219211 -0.047784  0.337363 -0.337504 -0.177875  0.259522   \n",
       "3     0.127328  0.454065 -0.015395  0.324827 -0.355668 -0.181511  0.409551   \n",
       "4     0.377168  0.415898 -0.106854  0.104183  0.002857 -0.044235  0.065276   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "4130  0.261183  0.286592 -0.118561  0.118936  0.104597 -0.022623  0.111784   \n",
       "4131  0.175034  0.276350 -0.197199 -0.011872  0.084094 -0.155784  0.166965   \n",
       "4132  0.212616  0.196570 -0.204271  0.044122  0.007528 -0.147028  0.139173   \n",
       "4133  0.238229  0.155935 -0.138760 -0.030620  0.082870  0.029618  0.092275   \n",
       "4134  0.275128  0.242884 -0.190589  0.027736  0.210177  0.070173  0.021179   \n",
       "\n",
       "             7         8         9  ...       291       292       293  \\\n",
       "0     0.404252  0.298668  0.086156  ... -0.096112  0.443278 -0.128233   \n",
       "1     0.370823  0.328146  0.134766  ... -0.103543  0.399193 -0.124846   \n",
       "2     0.174175  0.315422  0.243993  ...  0.002533  0.536723  0.089167   \n",
       "3     0.378628  0.283049  0.192282  ... -0.037144  0.382995 -0.140089   \n",
       "4    -0.101596  0.252312  0.264270  ...  0.202337  0.523531 -0.009183   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "4130 -0.200460  0.275091  0.311861  ... -0.010332  0.494125  0.076149   \n",
       "4131 -0.173581  0.193364  0.237430  ...  0.093888  0.437278  0.024422   \n",
       "4132 -0.128615  0.216669  0.224261  ...  0.088273  0.446130 -0.006519   \n",
       "4133 -0.177611  0.238138  0.309292  ...  0.086252  0.566144  0.112057   \n",
       "4134 -0.257775  0.294246  0.277073  ...  0.142902  0.431740  0.104178   \n",
       "\n",
       "           294       295       296       297       298       299  y  \n",
       "0     0.235329  0.169030  0.338615 -0.160767  0.040528  0.301025  0  \n",
       "1     0.311998  0.217576  0.335280 -0.184212  0.023380  0.276236  0  \n",
       "2     0.151804  0.173900  0.226834 -0.034279  0.160243  0.231921  0  \n",
       "3     0.290213  0.127780  0.332279 -0.121677  0.120118  0.320373  0  \n",
       "4     0.320289  0.304284  0.008000  0.145484  0.176826  0.591520  0  \n",
       "...        ...       ...       ...       ...       ...       ... ..  \n",
       "4130  0.288994  0.324444 -0.034715  0.127440  0.177613  0.509514  0  \n",
       "4131  0.260227  0.329413 -0.067035  0.169661  0.155913  0.517603  0  \n",
       "4132  0.148696  0.271967  0.048124  0.204842  0.145011  0.401621  0  \n",
       "4133  0.301727  0.386718 -0.013566  0.137317  0.223767  0.488651  0  \n",
       "4134  0.211724  0.319531  0.063401  0.137556  0.258983  0.656513  0  \n",
       "\n",
       "[4135 rows x 301 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cb2cab8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import minmax_scale\n",
    "scale = minmax_scale(data.iloc[:,:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4dc02d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test= train_test_split(scale,data.iloc[:,-1],test_size=0.3,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6664f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naive Bayes\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "# 建置模型與訓練\n",
    "start = time.time()\n",
    "model = MultinomialNB()\n",
    "model.fit(X_train, y_train)\n",
    "end = time.time()\n",
    "print('花費時間:', end-start)\n",
    "# 準確率\n",
    "print('訓練accuracy:',LR.score(X_train,y_train))\n",
    "print('測試accuracy:',LR.score(X_test,y_test))\n",
    "#儲存模型\n",
    "dump(model, 'NB.joblib') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecd3b253",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# 建置模型與訓練\n",
    "start = time.time()\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "end = time.time()\n",
    "print('花費時間:', end-start)\n",
    "# 準確率\n",
    "print('訓練accuracy:',LR.score(X_train,y_train))\n",
    "print('測試accuracy:',LR.score(X_test,y_test))\n",
    "#儲存模型\n",
    "dump(model, 'LR.joblib') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "680ce6de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# 建置模型與訓練\n",
    "start = time.time()\n",
    "model = RandomForestClassifier(random_state=0)\n",
    "model.fit(X_train, y_train)\n",
    "end = time.time()\n",
    "print('花費時間:', end-start)\n",
    "# 準確率\n",
    "print('訓練accuracy:',LR.score(X_train,y_train))\n",
    "print('測試accuracy:',LR.score(X_test,y_test))\n",
    "#儲存模型\n",
    "dump(model, 'RF.joblib') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b36f356",
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "# 建置模型與訓練\n",
    "start = time.time()\n",
    "model = KNeighborsClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "end = time.time()\n",
    "print('花費時間:', end-start)\n",
    "# 準確率\n",
    "print('訓練accuracy:',LR.score(X_train,y_train))\n",
    "print('測試accuracy:',LR.score(X_test,y_test))\n",
    "#儲存模型\n",
    "dump(model, 'KNN.joblib') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f736cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AdaBoost\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "# 建置模型與訓練\n",
    "start = time.time()\n",
    "model = AdaBoostClassifier(random_state=0)\n",
    "model.fit(X_train, y_train)\n",
    "end = time.time()\n",
    "print('花費時間:', end-start)\n",
    "# 準確率\n",
    "print('訓練accuracy:',LR.score(X_train,y_train))\n",
    "print('測試accuracy:',LR.score(X_test,y_test))\n",
    "#儲存模型\n",
    "dump(model, 'AdaB.joblib') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71988af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost\n",
    "from xgboost import XGBClassifier\n",
    "# 建置模型與訓練\n",
    "start = time.time()\n",
    "model = XGBClassifier(random_state=0)\n",
    "model.fit(X_train, y_train)\n",
    "end = time.time()\n",
    "print('花費時間:', end-start)\n",
    "# 準確率\n",
    "print('訓練accuracy:',LR.score(X_train,y_train))\n",
    "print('測試accuracy:',LR.score(X_test,y_test))\n",
    "#儲存模型\n",
    "dump(model, 'XGB.joblib') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e8a37cce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_13 (Dense)            (None, 256)               77056     \n",
      "                                                                 \n",
      " activation_13 (Activation)  (None, 256)               0         \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 128)               32896     \n",
      "                                                                 \n",
      " activation_14 (Activation)  (None, 128)               0         \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 9)                 1161      \n",
      "                                                                 \n",
      " activation_15 (Activation)  (None, 9)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 111,113\n",
      "Trainable params: 111,113\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# DNN\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation\n",
    "# 建置模型\n",
    "inputdim = X_train.shape[1]\n",
    "model = Sequential()\n",
    "model.add(Dense(256, input_dim=inputdim))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(128))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(9))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0ced6543",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "82/82 [==============================] - 1s 8ms/step - loss: 0.0483 - accuracy: 0.9973 - val_loss: 8.2941e-06 - val_accuracy: 1.0000\n",
      "Epoch 2/10\n",
      "82/82 [==============================] - 0s 4ms/step - loss: 5.6209e-05 - accuracy: 1.0000 - val_loss: 4.7682e-07 - val_accuracy: 1.0000\n",
      "Epoch 3/10\n",
      "82/82 [==============================] - 0s 4ms/step - loss: 1.0477e-05 - accuracy: 1.0000 - val_loss: 1.3524e-07 - val_accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "82/82 [==============================] - 0s 4ms/step - loss: 4.2565e-06 - accuracy: 1.0000 - val_loss: 7.0703e-08 - val_accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "82/82 [==============================] - 0s 4ms/step - loss: 2.5520e-06 - accuracy: 1.0000 - val_loss: 3.5352e-08 - val_accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "82/82 [==============================] - 0s 4ms/step - loss: 1.6580e-06 - accuracy: 1.0000 - val_loss: 2.0553e-08 - val_accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "82/82 [==============================] - 0s 4ms/step - loss: 1.1535e-06 - accuracy: 1.0000 - val_loss: 1.2743e-08 - val_accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "82/82 [==============================] - 0s 4ms/step - loss: 8.2812e-07 - accuracy: 1.0000 - val_loss: 9.0435e-09 - val_accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "82/82 [==============================] - 0s 4ms/step - loss: 6.2593e-07 - accuracy: 1.0000 - val_loss: 5.3439e-09 - val_accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "82/82 [==============================] - 0s 4ms/step - loss: 4.8063e-07 - accuracy: 1.0000 - val_loss: 4.5217e-09 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x240ebcbf9a0>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 訓練模型\n",
    "model.fit(x=X_train,y=y_train, validation_split=0.1, epochs=10, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d498e73",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# DNN\n",
    "# 測試集的準確率\n",
    "model.evaluate(X_test, y_test ,batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c821341",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DNN\n",
    "# 儲存模型\n",
    "from keras.models import load_model\n",
    "model.save('DNN')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
